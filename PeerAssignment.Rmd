---
title: "Practical Machine Learning Peer Review Project"
author: "KEE"
date: "March 15, 2017"
output: html_document
subtitle: In this project, machine learning technique will be apply to build a model quantifing the correctness of weight lifting exercise base on data collected from wearable accelerometer devices.
---

## Loading and preprocessing the data
Load required libraries
```{r, warning=FALSE, error=FALSE, message=FALSE}
library(caret)
library(parallel)
library(doParallel)
```

Load data, gethers machine learning related data:  
 - filter non-accelerometers columns and NA columns
```{r, warning=FALSE, error=FALSE, message=FALSE}
train <- read.csv("pml-training.csv", header = TRUE, as.is = TRUE)
test  <- read.csv("pml-testing.csv",  header = TRUE, as.is = TRUE)

# Filter non-accelerometers data
train <- train[,8:ncol(train)]
 test <-  test[,8:ncol( test)]

# Filter if 80% of a column in testing or training data are NA
 naListTest <- lapply((lapply( test, is.na)), sum)
naListTrain <- lapply((lapply(train, is.na)), sum)
naFilter <- naListTest > 0.8*nrow(test) | naListTrain > 0.8*nrow(train)
 f_test <-  test[,!naFilter]
f_train <- train[,!naFilter]

# Check if any value is still NA
sum(sapply( f_test , is.na))
sum(sapply( f_train, is.na))
```

Filter correlated Columns and zero covariates columns 
```{r, warning=FALSE, error=FALSE, message=FALSE}
# Filter Correlated Columns
corrList <- findCorrelation(cor(f_train[,-ncol(f_train)]), verbose = TRUE)
f_train <- f_train[,-corrList]
f_test  <- f_test [,-corrList]

# Filter zero covariates
nzv <- nearZeroVar(f_train[,-ncol(f_train)], saveMetrics = TRUE)
f_train <- f_train[,!nzv$nzv]
f_test  <- f_test [,!nzv$nzv]

# Prepare cross validation data
set.seed(1)
inTrain <- createDataPartition(f_train$classe, p = 0.7, list = FALSE)
v_train <- f_train[inTrain,]
v_valid <- f_train[-inTrain,]
```

# Model Building
Fit machine learning model with 4 different methods and get their in sample accuracy.  
"doParallel" library is applied to speed up the training.  
```{r, cache=TRUE, warning=FALSE, error=FALSE, message=FALSE}
cluster <- makeCluster(detectCores())
registerDoParallel(cluster)

fitControl <- trainControl(method = "cv",
                           number = 10,
                           allowParallel = TRUE)
				
# Classification tree
fit_rpart <- train(classe ~ ., data=v_train, trControl = fitControl, method="rpart")
cnf_rpart <- confusionMatrix(predict(fit_rpart, newdata=v_train), v_train$classe)

# Random forest
fit_rf <- train(classe ~ ., data=v_train, trControl = fitControl, method="rf")
cnf_rf <- confusionMatrix(predict(fit_rf, newdata=v_train), v_train$classe)

# Boosted trees
fit_gbm <- train(classe ~ ., data=v_train, trControl = fitControl, method="gbm")
cnf_gbm <- confusionMatrix(predict(fit_gbm, newdata=v_train), v_train$classe)

# Linear discriminant analysis
fit_lda <- train(classe ~ ., data=v_train, trControl = fitControl, method="lda")
cnf_lda <- confusionMatrix(predict(fit_lda, newdata=v_train), v_train$classe)
```
### Accuracy in training data:  
Classification tree: `r round(cnf_rpart$overall['Accuracy'], 2)`  
Random forest: `r round(cnf_rf$overall['Accuracy'], 2)`  
Boosted trees: `r round(cnf_gbm$overall['Accuracy'], 2)`  
Linear discriminant analysis: `r round(cnf_lda$overall['Accuracy'], 2)`  

# Cross Validation
Cross validation fitted model to get out of sample accuracy.   
```{r, warning=FALSE, error=FALSE, message=FALSE}
vcnf_rpart <- confusionMatrix(predict(fit_rpart, newdata=v_valid), v_valid$classe)
vcnf_rf <- confusionMatrix(predict(fit_rf, newdata=v_valid), v_valid$classe)
vcnf_gbm <- confusionMatrix(predict(fit_gbm, newdata=v_valid), v_valid$classe)
vcnf_lda <- confusionMatrix(predict(fit_lda, newdata=v_valid), v_valid$classe)
```

### Accuracy in validation data:  
Classification tree: `r round(vcnf_rpart$overall['Accuracy'], 2)`  
Random forest: `r round(vcnf_rf$overall['Accuracy'], 2)`  
Boosted trees: `r round(vcnf_gbm$overall['Accuracy'], 2)`  
Linear discriminant analysis: `r round(vcnf_lda$overall['Accuracy'], 2)`  

# Exprected Out of Sample Error
Calculate exprected out of sample error.   
```{r, warning=FALSE, error=FALSE, message=FALSE}
oose_rpart <- 1-sum(diag(vcnf_rpart$table))/sum(vcnf_rpart$table)
oose_rf    <- 1-sum(diag(   vcnf_rf$table))/sum(   vcnf_rf$table)
oose_gbm   <- 1-sum(diag(  vcnf_gbm$table))/sum(  vcnf_gbm$table)
oose_lda   <- 1-sum(diag(  vcnf_lda$table))/sum(  vcnf_lda$table)
```

### Exprected Out of sample error:  
Classification tree: `r round(oose_rpart, 2)`  
Random forest: `r round(oose_rf, 2)`  
Boosted trees: `r round(oose_gbm, 2)`  
Linear discriminant analysis: `r round(oose_lda, 2)` 

# Model Choosing
Model choosen is **Random forest**, which is with lowest exprected out of sample error.   
Although it took rather long time to train, but it worth the effort.  

# Predicting Test Cases
Predict test case with fitted model.  
```{r, warning=FALSE, error=FALSE, message=FALSE}
predict(fit_rf, newdata=f_test)
```
